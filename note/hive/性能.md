http://www.csdn.net/article/2015-01-13/2823530
http://blog.javachen.com/2013/09/04/how-to-decide-map-number.html

### 输入的map数
    hive> set hive.input.format;
    hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;

mapreduce.input.fileinputformat.split.minsize  默认256MB
mapreduce.input.fileinputformat.split.maxsize  默认1
mapreduce.input.fileinputformat.split.minsize.per.rack 默认1
mapreduce.input.fileinputformat.split.minsize.per.node 默认1

一般来说如果小文件比较多的时候后面3个参数需要调大，否则的话会启动很多map任务

运行时间相差不大，但能节省资源
输出文件数据减少，方便后续作业 



### 输出的map数
hive.merge.mapfiles(默认为true)
正常的map-only job后，是否启动merge job来合并map端输出的结果
hive.merge.mapredfiles(默认为false)
正常的map-reduce job后，是否启动merge job来合并reduce端输出的结果，建议开启
hive.merge.smallfiles.avgsize(默认为16MB)
如果不是partitioned table的话，输出table文件的平均大小小于这个值，启动merge job，如果是partitioned table，则分别计算每个partition下文件平均大小，只merge平均大小小于这个值的partition。这个值只有当hive.merge.mapfiles或hive.merge.mapredfiles设定为true时，才有效

所以可以将hive.merge.mapfiles/hive.merge.mapredfiles 设为true,再调整hive.merge.smallfiles.avgsize才能生效

>>有动态分区的时候不启作用


### 小文件
输出小文件太多时
set hive.merge.smallfiles.avgsize 小文件的大小，默认比较小，可以设置到256或512M或更大
set hive.merge.mapfiles=true  合并输入文件，只有map任务时
set hive.merge.mapredfiles=true  合并输入文件，只有map任务时
以上两个参数同时启作用，如果小文件标准设置太小，全并的效果还是达不到
>>textfile 格式时，ORCFile格式不启作用



### mapjoin 
方法一：
在Hive0.11前，必须使用MAPJOIN来标记显示地启动该优化操作，由于其需要将小表加载进内存所以要注意小表的大小
SELECT /*+ MAPJOIN(smalltable)*/  .key,value
FROM smalltable JOIN bigtable ON smalltable.key = bigtable.key
方法二：
在Hive0.11后，Hive默认启动该优化，也就是不在需要显示的使用MAPJOIN标记，其会在必要的时候触发该优化操作将普通JOIN转换成MapJoin，可以通过以下两个属性来设置该优化的触发时机
hive.auto.convert.join
默认值为true，自动开户MAPJOIN优化
hive.mapjoin.smalltable.filesize


hive.auto.convert.join为true且表大小不超过hive.mapjoin.smalltable.filesize时

set hive.map.aggr=true (开启map端combiner); //在Map端做combiner,假如map各条数据基本上不一样, 聚合没什么意义，做combiner反而画蛇添足,hive里也考虑的比较周到通过参数hive.groupby.mapaggr.checkinterval = 100000 (默认)
hive.map.aggr.hash.min.reduction=0.5(默认)
两个参数的意思是：预先取100000条数据聚合,如果聚合后的条数/100000>0.5，则不再聚合
 
set hive.groupby.skewindata=true；//决定 group by 操作是否支持倾斜的数据。注意：只能对单个字段聚合.控制生成两个MR Job,第一个MR Job Map的输出结果随机分配到reduce做次预汇总,减少某些key值条数过多某些key条数过小造成的数据倾斜问题


## 其它
多表关联时，如果关联键为同一字段，则会转化成一个Job,否则会转化成多个Job


#explain
explain sql;




####




小文件问题的影响
1.从Hive的角度看，小文件会开很多map，一个map开一个JVM去执行，所以这些任务的初始化，启动，执行会浪费大量的资源，严重影响性能。
2.在HDFS中，每个小文件对象约占150byte，如果小文件过多会占用大量内存。这样NameNode内存容量严重制约了集群的扩展。


小文件是如何产生的
1.动态分区插入数据，产生大量的小文件，从而导致map数量剧增。
2.reduce数量越多，小文件也越多(reduce的个数和输出文件是对应的)。
3.数据源本身就包含大量的小文件。
4.小批量多次写入，表存储为textfile时


对于已有的小文件，我们可以通过以下几种方案解决：
1.使用hadoop archive命令把小文件进行归档。
2.做中间表，从中间表写入最终表时控制输出文件大小。
3.通过参数进行调节，设置map/reduce端的相关参数，如下：

设置map输入合并小文件的相关参数：
//每个Map最大输入大小(这个值决定了合并后文件的数量)  
set mapred.max.split.size=256000000;    
//一个节点上split的至少的大小(这个值决定了多个DataNode上的文件是否需要合并)  
set mapred.min.split.size.per.node=100000000;  
//一个交换机下split的至少的大小(这个值决定了多个交换机上的文件是否需要合并)    
set mapred.min.split.size.per.rack=100000000;  
//执行Map前进行小文件合并  
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat; 



http://www.cnblogs.com/thinkpad/p/5173636.html

Hive query将运算好的数据写回hdfs（比如insert into语句），有时候会产生大量的小文件，如果不采用CombineHiveInputFormat就对这些小文件进行操作的话会产生大量的map task，耗费大量集群资源，而且小文件过多会对namenode造成很大压力。所以Hive在正常job执行完之后，会起一个conditional task，来判断是否需要合并小文件，如果满足要求就会另外启动一个map-only job 或者mapred job来完成合并



参数解释
h    


hive.merge.mapfiles(默认为true)
正常的map-only job后，是否启动merge job来合并map端输出的结果


hive.merge.mapredfiles(默认为false)
正常的map-reduce job后，是否启动merge job来合并reduce端输出的结果，建议开启





hive.exec.reducers.bytes.per.reducer(默认为1G)
如果用户不主动设置mapred.reduce.tasks数，则会根据input directory计算出所有读入文件的input summary size，然后除以这个值算出reduce number
   reducers = (int) ((totalInputFileSize + bytesPerReducer - 1) / bytesPerReducer);
   reducers = Math.max(1, reducers);
   reducers = Math.min(maxReducers, reducers);


hive.merge.size.per.task(默认是256MB)
merge job后每个文件的目标大小（targetSize），用之前job输出文件的total size除以这个值，就可以决定merge job的reduce数目。merge job的map端相当于identity map，然后shuffle到reduce，每个reduce dump一个文件，通过这种方式控制文件的数量和大小

MapredWork work = (MapredWork) mrTask.getWork();
if (work.getNumReduceTasks() > 0) {
     int maxReducers = conf.getIntVar(HiveConf.ConfVars.MAXREDUCERS);
     int reducers = (int) ((totalSize +targetSize - 1) / targetSize);
     reducers = Math.max(1, reducers);
     reducers = Math.min(maxReducers, reducers);
     work.setNumReduceTasks(reducers);
}


mapred.max.split.size(默认256MB)
mapred.min.split.size.per.node(默认1 byte)
mapred.min.split.size.per.rack(默认1 byte)
这三个参数CombineFileInputFormat中会使用，Hive默认的InputFormat是CombineHiveInputFormat，里面所有的调用（包括最重要的getSplits和getRecordReader）都会转换成CombineFileInputFormat的调用，所以可以看成是它的一个包装。CombineFileInputFormat 可以将许多小文件合并成一个map的输入，如果文件很大，也可以对大文件进行切分，分成多个map的输入。一个CombineFileSplit对应一个map的输入，包含一组path(hdfs路径list)，startoffset, lengths, locations(文件所在hostname list)mapred.max.split.size是一个split 最大的大小，mapred.min.split.size.per.node是一个节点上（datanode）split至少的大小，mapred.min.split.size.per.rack是同一个交换机(rack locality)下split至少的大小通过这三个数的调节，组成了一串CombineFileSplit用户可以通过增大mapred.max.split.size的值来减少Map Task数量








http://www.dataguru.cn/article-3269-1.html